{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai"
      ],
      "metadata": {
        "id": "fPq7jPuE3eUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Install the Google AI Python SDK\n",
        "\n",
        "$ pip install google-generativeai\n",
        "\n",
        "See the getting started guide for more information:\n",
        "https://ai.google.dev/gemini-api/docs/get-started/python\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "gemini_flash= \"AIzaSyBvZVM70EwOKa-GJew00m4quQt4RtPtBwE\"\n",
        "\n",
        "\n",
        "genai.configure(api_key=gemini_flash)\n",
        "\n",
        "def upload_to_gemini(path, mime_type=None):\n",
        "  \"\"\"Uploads the given file to Gemini.\n",
        "\n",
        "  See https://ai.google.dev/gemini-api/docs/prompting_with_media\n",
        "  \"\"\"\n",
        "  file = genai.upload_file(path, mime_type=mime_type)\n",
        "  print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
        "  return file\n",
        "\n",
        "\n",
        "def gemini(prompt,image_path):\n",
        "\n",
        "  # Create the model\n",
        "  # See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
        "  generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 64,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "  }\n",
        "  safety_settings = [\n",
        "    # {\n",
        "    #   \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "    #   \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    # },\n",
        "    # {\n",
        "    #   \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "    #   \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    # },\n",
        "    # {\n",
        "    #   \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "    #   \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    # },\n",
        "    # {\n",
        "    #   \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "    #   \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
        "    # },\n",
        "  ]\n",
        "\n",
        "  model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    safety_settings=safety_settings,\n",
        "    generation_config=generation_config,\n",
        "  )\n",
        "\n",
        "  # TODO Make these files available on the local file system\n",
        "  # You may need to update the file paths\n",
        "  files = [\n",
        "    upload_to_gemini(image_path, mime_type=\"image/jpeg\"),\n",
        "  ]\n",
        "\n",
        "  chat_session = model.start_chat(\n",
        "    history=[\n",
        "      {\n",
        "        \"role\": \"user\",\n",
        "        \"parts\": [\n",
        "          files[0],\n",
        "        ],\n",
        "      },\n",
        "    ]\n",
        "  )\n",
        "  fflag = True\n",
        "  try:\n",
        "    response = chat_session.send_message(prompt)\n",
        "  except:\n",
        "    fflag = False\n",
        "    pass\n",
        "  if fflag:\n",
        "    print(response.text)\n",
        "\n",
        "    gen_text = response.text\n",
        "\n",
        "    return gen_text\n",
        "  else:\n",
        "    return \"ERROR\""
      ],
      "metadata": {
        "id": "-7YnlSPI2mT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install jiwer"
      ],
      "metadata": {
        "id": "9TwZytu8K59A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jiwer import cer\n",
        "from jiwer import wer\n",
        "def cer_wer(generated_text, ground_truth):\n",
        "  cer_error = cer(ground_truth,generated_text)\n",
        "  wer_error = wer(ground_truth,generated_text)\n",
        "  return cer_error, wer_error"
      ],
      "metadata": {
        "id": "d6rSLwoQK5AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import math\n",
        "import time\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "data_path = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/ocr_dataset_small.json\"\n",
        "image_folder = \"/content/drive/MyDrive/ocr_data/images\"\n",
        "pad10_image_folder =  \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image10\"\n",
        "pad20_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image20\"\n",
        "master_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/images\"\n",
        "\n",
        "\n",
        "annotation_path = r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/master_dataset.json\"\n",
        "\n",
        "# model_vicuna.to(device)\n",
        "with open(data_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "#\n",
        "\n",
        "img_count = {}\n",
        "labels = []\n",
        "filt_data = []\n",
        "for d in data:\n",
        "  image_name = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "  if (len(filt_data) < 25):\n",
        "    if not \"signature\" in d[\"label_name\"].lower():\n",
        "      if image_name not in list(img_count.keys()):\n",
        "\n",
        "        img_count[image_name] = []\n",
        "\n",
        "      if (len(img_count[image_name])<5):\n",
        "        # else:\n",
        "        img_count[image_name].append(image_name)\n",
        "        labels.append(d[\"label_name\"])\n",
        "        filt_data.append(d)\n",
        "\n",
        "# filt_data = filt_data[:1]\n",
        "evaluated_data = []\n",
        "model_name = \"gemini-flash-original\"\n",
        "\n",
        "with open(annotation_path, 'r', encoding='utf8') as fin:\n",
        "    orig_annotation = json.load(fin)\n",
        "\n",
        "images = orig_annotation[\"images\"]\n",
        "annotations = orig_annotation[\"annotations\"]\n",
        "categories = orig_annotation[\"categories\"]\n",
        "\n",
        "\n",
        "unique_image_list = []\n",
        "LRVQA = []\n",
        "\n",
        "\n",
        "for d in filt_data:\n",
        "    # print(\"Data\",data[i])\n",
        "\n",
        "\n",
        "\n",
        "    img_path = os.path.join(image_folder, d['image_path'])\n",
        "\n",
        "    p_img_path = os.path.join(pad10_image_folder, d['image_path'])\n",
        "    pp_img_path = os.path.join(pad20_image_folder, d['image_path'])\n",
        "\n",
        "    root_img = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "    full_img_path = os.path.join(master_image_folder, root_img )\n",
        "\n",
        "    # hwr_image = Image.open(img_path).convert(\"RGB\")\n",
        "    # p_img = Image.open(p_img_path).convert(\"RGB\")\n",
        "    # pp_img = Image.open(pp_img_path).convert(\"RGB\")\n",
        "    # full_img = Image.open(full_img_path).convert(\"RGB\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    filtered_img = [img for img in images if img[\"file_name\"] == root_img]\n",
        "    filtered_img = filtered_img[0]\n",
        "\n",
        "    filtered_id = filtered_img[\"id\"]\n",
        "\n",
        "    filtered_annotation = [ann for ann in annotations if ann[\"image_id\"] == filtered_id]\n",
        "    label_bbox = []\n",
        "    for each_ann in filtered_annotation:\n",
        "      cat_id = each_ann[\"category_id\"]\n",
        "      category_name = [cat[\"name\"] for cat in categories if cat[\"id\"] == cat_id]\n",
        "      category_name = category_name[0]\n",
        "      if category_name == d[\"label_name\"]:\n",
        "        label_bbox = each_ann[\"bbox\"]\n",
        "\n",
        "    qs = d['question']\n",
        "    qs = qs+\" Answer:\"\n",
        "    # prompt = \"Question:\" + qs + \"? Answer:\"\n",
        "\n",
        "    hwr_prompt =  qs\n",
        "\n",
        "    label_name = d[\"label_name\"]\n",
        "    label_qs = \"what is the \" + label_name + \" written in the image? Answer:\"\n",
        "    print(\"question\", qs)\n",
        "\n",
        "    bb_qs = \"what is the bounding box for \" + label_name + \"in the image?\"+  \" Answer:\"\n",
        "\n",
        "    time_qs = \"What is the difference in time between the occurrence of the event and when it was reported?\"+  \" Answer:\"\n",
        "\n",
        "    bail_qs = \"\"\"Are the charges against accused bailable or not? If any of the charges are non-bailable answer \"Non-bailable\" else \"Bailable\".\"\"\"+  \" Answer:\"\n",
        "\n",
        "    print(\"task-hwr\")\n",
        "    hwr = gemini(hwr_prompt,img_path)\n",
        "    print(\"task-phwr\")\n",
        "    time.sleep(10)\n",
        "    phwr = gemini(hwr_prompt,p_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-pphwr\")\n",
        "\n",
        "    pphwr = gemini(hwr_prompt,pp_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_hwr\")\n",
        "    l_hwr = gemini(label_qs,img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_phwr\")\n",
        "    l_phwr = gemini(label_qs,p_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_pphwr\")\n",
        "    l_pphwr = gemini(label_qs,pp_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-doc_vqa\")\n",
        "    doc_vqa = gemini(label_qs,full_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-bb\")\n",
        "    bb_vqa = gemini(bb_qs,full_img_path)\n",
        "    time.sleep(5)\n",
        "\n",
        "\n",
        "    if full_img_path not in unique_image_list:\n",
        "      print(\"task-time\")\n",
        "      time_vqa = gemini(time_qs,full_img_path)\n",
        "      time.sleep(5)\n",
        "      print(\"task-bail\")\n",
        "      bail_vqa = gemini(bail_qs,full_img_path)\n",
        "      time.sleep(5)\n",
        "      content = {\"time_vqa\":time_vqa,\"bail_vqa\":bail_vqa,\"time_qs\":time_qs,\"bail_qs\":bail_qs,\"image_name\":full_img_path,\"time_gt\":\"\",\"bail_gt\":\"\"}\n",
        "      LRVQA.append(content)\n",
        "      unique_image_list.append(full_img_path)\n",
        "\n",
        "\n",
        "\n",
        "    ## evaluation\n",
        "    ground_truth = d[\"answers\"]\n",
        "\n",
        "    try:\n",
        "      hwr_cer_error, hwr_wer_error = cer_wer(hwr, ground_truth)\n",
        "    except:\n",
        "      hwr_cer_error, hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      phwr_cer_error, phwr_wer_error = cer_wer(phwr, ground_truth)\n",
        "    except:\n",
        "      phwr_cer_error, phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      pphwr_cer_error, pphwr_wer_error = cer_wer(pphwr, ground_truth)\n",
        "    except:\n",
        "      pphwr_cer_error, pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = cer_wer(l_hwr, ground_truth)\n",
        "    except:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = cer_wer(l_phwr, ground_truth)\n",
        "    except:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = cer_wer(l_pphwr, ground_truth)\n",
        "    except:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      doc_vqa_cer_error, doc_vqa_wer_error = cer_wer(doc_vqa, ground_truth)\n",
        "    except:\n",
        "      doc_vqa_cer_error, doc_vqawer_error = 100,100\n",
        "\n",
        "    d[\"hwr_cer\"] = hwr_cer_error\n",
        "    d[\"hwr_wer\"] = hwr_wer_error\n",
        "    d[\"hwr_model_output\"] = hwr\n",
        "    d[\"hwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"phwr_cer\"] = phwr_cer_error\n",
        "    d[\"phwr_wer\"] = phwr_wer_error\n",
        "    d[\"phwr_model_output\"] = phwr\n",
        "    d[\"phwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"pphwr_cer\"] = pphwr_cer_error\n",
        "    d[\"pphwr_wer\"] = pphwr_wer_error\n",
        "    d[\"pphwr_model_output\"] = pphwr\n",
        "    d[\"pphwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"l_hwr_cer\"] = l_hwr_cer_error\n",
        "    d[\"l_hwr_wer\"] = l_hwr_wer_error\n",
        "    d[\"l_hwr_model_output\"] = l_hwr\n",
        "    d[\"l_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_phwr_cer\"] = l_phwr_cer_error\n",
        "    d[\"l_phwr_wer\"] = l_phwr_wer_error\n",
        "    d[\"l_phwr_model_output\"] = l_phwr\n",
        "    d[\"l_phwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_pphwr_cer\"] = l_pphwr_cer_error\n",
        "    d[\"l_pphwr_wer\"] = l_pphwr_wer_error\n",
        "    d[\"l_pphwr_model_output\"] = l_pphwr\n",
        "    d[\"l_pphwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"doc_vqa_cer\"] = doc_vqa_cer_error\n",
        "    d[\"doc_vqa_wer\"] = doc_vqa_wer_error\n",
        "    d[\"doc_vqa_model_output\"] = doc_vqa\n",
        "    d[\"doc_vqa_hwr_prompt\"] = label_qs\n",
        "\n",
        "\n",
        "\n",
        "    d[\"bbox_model_output\"] = bb_vqa\n",
        "    d[\"bbox_hwr_prompt\"] = bb_qs\n",
        "\n",
        "    d[\"model_name\"] = model_name\n",
        "\n",
        "    evaluated_data.append(d)\n",
        "\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR-25\"}.json'), 'w') as outfile:\n",
        "    json.dump(evaluated_data, outfile)\n",
        "\n",
        "print(LRVQA)\n",
        "LRVQA = json.dumps(LRVQA)\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA-25\"}.json'), 'w') as outfile:\n",
        "    json.dump(LRVQA,outfile)"
      ],
      "metadata": {
        "id": "jBCvXSaWKSPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import math\n",
        "import time\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "image_folder = \"/content/drive/MyDrive/ocr_data/images\"\n",
        "pad10_image_folder =  \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image10\"\n",
        "pad20_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image20\"\n",
        "master_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/images\"\n",
        "\n",
        "\n",
        "annotation_path = r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/master_dataset.json\"\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/ocr_dataset_small.json\"\n",
        "# model_vicuna.to(device)\n",
        "with open(data_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "#\n",
        "\n",
        "img_count = {}\n",
        "labels = []\n",
        "filt_data = []\n",
        "for d in data:\n",
        "  image_name = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "  if (len(filt_data) < 100):\n",
        "    if not \"signature\" in d[\"label_name\"].lower():\n",
        "      if image_name not in list(img_count.keys()):\n",
        "\n",
        "        img_count[image_name] = []\n",
        "\n",
        "      if (len(img_count[image_name])<5):\n",
        "        # else:\n",
        "        img_count[image_name].append(image_name)\n",
        "        labels.append(d[\"label_name\"])\n",
        "        filt_data.append(d)\n",
        "\n",
        "# filt_data = filt_data[:1]\n",
        "evaluated_data = []\n",
        "model_name = \"gemini-flash-original\"\n",
        "\n",
        "with open(annotation_path, 'r', encoding='utf8') as fin:\n",
        "    orig_annotation = json.load(fin)\n",
        "\n",
        "images = orig_annotation[\"images\"]\n",
        "annotations = orig_annotation[\"annotations\"]\n",
        "categories = orig_annotation[\"categories\"]\n",
        "\n",
        "\n",
        "unique_image_list = []\n",
        "LRVQA = []\n",
        "\n",
        "\n",
        "for d in filt_data:\n",
        "    # print(\"Data\",data[i])\n",
        "\n",
        "\n",
        "\n",
        "    img_path = os.path.join(image_folder, d['image_path'])\n",
        "\n",
        "    p_img_path = os.path.join(pad10_image_folder, d['image_path'])\n",
        "    pp_img_path = os.path.join(pad20_image_folder, d['image_path'])\n",
        "\n",
        "    root_img = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "    full_img_path = os.path.join(master_image_folder, root_img )\n",
        "\n",
        "    # hwr_image = Image.open(img_path).convert(\"RGB\")\n",
        "    # p_img = Image.open(p_img_path).convert(\"RGB\")\n",
        "    # pp_img = Image.open(pp_img_path).convert(\"RGB\")\n",
        "    # full_img = Image.open(full_img_path).convert(\"RGB\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    filtered_img = [img for img in images if img[\"file_name\"] == root_img]\n",
        "    filtered_img = filtered_img[0]\n",
        "\n",
        "    filtered_id = filtered_img[\"id\"]\n",
        "\n",
        "    filtered_annotation = [ann for ann in annotations if ann[\"image_id\"] == filtered_id]\n",
        "    label_bbox = []\n",
        "    for each_ann in filtered_annotation:\n",
        "      cat_id = each_ann[\"category_id\"]\n",
        "      category_name = [cat[\"name\"] for cat in categories if cat[\"id\"] == cat_id]\n",
        "      category_name = category_name[0]\n",
        "      if category_name == d[\"label_name\"]:\n",
        "        label_bbox = each_ann[\"bbox\"]\n",
        "\n",
        "    qs = d['question']\n",
        "    qs = qs+\" Answer:\"\n",
        "    # prompt = \"Question:\" + qs + \"? Answer:\"\n",
        "\n",
        "    hwr_prompt =  qs\n",
        "\n",
        "    label_name = d[\"label_name\"]\n",
        "    label_qs = \"what is the \" + label_name + \" written in the image? Answer:\"\n",
        "    print(\"question\", qs)\n",
        "\n",
        "    bb_qs = \"what is the bounding box for \" + label_name + \"in the image?\"+  \" Answer:\"\n",
        "\n",
        "    time_qs = \"What is the difference in time between the occurrence of the event and when it was reported?\"+  \" Answer:\"\n",
        "\n",
        "    bail_qs = \"\"\"Are the charges against accused bailable or not? If any of the charges are non-bailable answer \"Non-bailable\" else \"Bailable\".\"\"\"+  \" Answer:\"\n",
        "\n",
        "    print(\"task-hwr\")\n",
        "    hwr = gemini(hwr_prompt,img_path)\n",
        "    print(\"task-phwr\")\n",
        "    time.sleep(10)\n",
        "    phwr = gemini(hwr_prompt,p_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-pphwr\")\n",
        "\n",
        "    pphwr = gemini(hwr_prompt,pp_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_hwr\")\n",
        "    l_hwr = gemini(label_qs,img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_phwr\")\n",
        "    l_phwr = gemini(label_qs,p_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-l_pphwr\")\n",
        "    l_pphwr = gemini(label_qs,pp_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-doc_vqa\")\n",
        "    doc_vqa = gemini(label_qs,full_img_path)\n",
        "    time.sleep(5)\n",
        "    print(\"task-bb\")\n",
        "    bb_vqa = gemini(bb_qs,full_img_path)\n",
        "    time.sleep(5)\n",
        "\n",
        "\n",
        "    if full_img_path not in unique_image_list:\n",
        "      print(\"task-time\")\n",
        "      time_vqa = gemini(time_qs,full_img_path)\n",
        "      time.sleep(5)\n",
        "      print(\"task-bail\")\n",
        "      bail_vqa = gemini(bail_qs,full_img_path)\n",
        "      time.sleep(5)\n",
        "      content = {\"time_vqa\":time_vqa,\"bail_vqa\":bail_vqa,\"time_qs\":time_qs,\"bail_qs\":bail_qs,\"image_name\":full_img_path,\"time_gt\":\"\",\"bail_gt\":\"\"}\n",
        "      LRVQA.append(content)\n",
        "      unique_image_list.append(full_img_path)\n",
        "\n",
        "\n",
        "\n",
        "    ## evaluation\n",
        "    ground_truth = d[\"answers\"]\n",
        "\n",
        "    try:\n",
        "      hwr_cer_error, hwr_wer_error = cer_wer(hwr, ground_truth)\n",
        "    except:\n",
        "      hwr_cer_error, hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      phwr_cer_error, phwr_wer_error = cer_wer(phwr, ground_truth)\n",
        "    except:\n",
        "      phwr_cer_error, phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      pphwr_cer_error, pphwr_wer_error = cer_wer(pphwr, ground_truth)\n",
        "    except:\n",
        "      pphwr_cer_error, pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = cer_wer(l_hwr, ground_truth)\n",
        "    except:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = cer_wer(l_phwr, ground_truth)\n",
        "    except:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = cer_wer(l_pphwr, ground_truth)\n",
        "    except:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      doc_vqa_cer_error, doc_vqa_wer_error = cer_wer(doc_vqa, ground_truth)\n",
        "    except:\n",
        "      doc_vqa_cer_error, doc_vqawer_error = 100,100\n",
        "\n",
        "    d[\"hwr_cer\"] = hwr_cer_error\n",
        "    d[\"hwr_wer\"] = hwr_wer_error\n",
        "    d[\"hwr_model_output\"] = hwr\n",
        "    d[\"hwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"phwr_cer\"] = phwr_cer_error\n",
        "    d[\"phwr_wer\"] = phwr_wer_error\n",
        "    d[\"phwr_model_output\"] = phwr\n",
        "    d[\"phwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"pphwr_cer\"] = pphwr_cer_error\n",
        "    d[\"pphwr_wer\"] = pphwr_wer_error\n",
        "    d[\"pphwr_model_output\"] = pphwr\n",
        "    d[\"pphwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"l_hwr_cer\"] = l_hwr_cer_error\n",
        "    d[\"l_hwr_wer\"] = l_hwr_wer_error\n",
        "    d[\"l_hwr_model_output\"] = l_hwr\n",
        "    d[\"l_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_phwr_cer\"] = l_phwr_cer_error\n",
        "    d[\"l_phwr_wer\"] = l_phwr_wer_error\n",
        "    d[\"l_phwr_model_output\"] = l_phwr\n",
        "    d[\"l_phwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_pphwr_cer\"] = l_pphwr_cer_error\n",
        "    d[\"l_pphwr_wer\"] = l_pphwr_wer_error\n",
        "    d[\"l_pphwr_model_output\"] = l_pphwr\n",
        "    d[\"l_pphwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"doc_vqa_cer\"] = doc_vqa_cer_error\n",
        "    d[\"doc_vqa_wer\"] = doc_vqa_wer_error\n",
        "    d[\"doc_vqa_model_output\"] = doc_vqa\n",
        "    d[\"doc_vqa_hwr_prompt\"] = label_qs\n",
        "\n",
        "\n",
        "\n",
        "    d[\"bbox_model_output\"] = bb_vqa\n",
        "    d[\"bbox_hwr_prompt\"] = bb_qs\n",
        "\n",
        "    d[\"model_name\"] = model_name\n",
        "\n",
        "    evaluated_data.append(d)\n",
        "\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR-100\"}.json'), 'w') as outfile:\n",
        "    json.dump(evaluated_data, outfile)\n",
        "\n",
        "print(LRVQA)\n",
        "LRVQA = json.dumps(LRVQA)\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA-100\"}.json'), 'w') as outfile:\n",
        "    json.dump(LRVQA,outfile)"
      ],
      "metadata": {
        "id": "1f5YqK07v7JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Azure MLLM**"
      ],
      "metadata": {
        "id": "PsrEPVrR56Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from mimetypes import guess_type\n",
        "\n",
        "# Function to encode a local image into data URL\n",
        "def local_image_to_data_url(image_path):\n",
        "    # Guess the MIME type of the image based on the file extension\n",
        "    mime_type, _ = guess_type(image_path)\n",
        "    if mime_type is None:\n",
        "        mime_type = 'application/octet-stream'  # Default MIME type if none is found\n",
        "\n",
        "    # Read and encode the image file\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')\n",
        "\n",
        "    # Construct the data URL\n",
        "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
        "\n",
        "# Example usage\n",
        "# image_path = '<path_to_image>'\n",
        "# data_url = local_image_to_data_url(image_path)\n",
        "# print(\"Data URL:\", data_url)"
      ],
      "metadata": {
        "id": "F1GYLJPcIQaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "GPT4V_KEY = \"7594755880f24244b3b161a1e6f56355\"\n",
        "\n",
        "\n",
        "def azure_mllm(prompt,img_url):\n",
        "    headers = {\n",
        "        \"Content-Type\": \"application/json\",\n",
        "        \"api-key\": GPT4V_KEY,\n",
        "    }\n",
        "\n",
        "    # Payload for the request\n",
        "    payload = {\n",
        "        \"messages\": [\n",
        "        {\n",
        "          \"role\": \"system\",\n",
        "          \"content\": [\n",
        "            {\n",
        "              \"type\": \"text\",\n",
        "              \"text\": \"You are an AI assistant that helps people find information.\"\n",
        "            }\n",
        "          ]\n",
        "        },\n",
        "            {\n",
        "          \"role\": \"user\",\n",
        "          \"content\": [\n",
        "            {\n",
        "              \"type\": \"image_url\",\n",
        "              \"image_url\": {\n",
        "                \"url\": img_url\n",
        "              }\n",
        "            },\n",
        "            {\n",
        "              \"type\": \"text\",\n",
        "              \"text\": prompt\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "        ],\n",
        "        \"max_tokens\": 800,\n",
        "        \"temperature\": 0.7,\n",
        "        \"top_p\": 0.95\n",
        "    }\n",
        "\n",
        "    GPT4V_ENDPOINT = \"https://cerebro-al-qa.openai.azure.com/openai/deployments/gpt-4-turbo/chat/completions?api-version=2024-02-15-preview\"\n",
        "\n",
        "    # Send request\n",
        "    fflag = True\n",
        "    try:\n",
        "        response = requests.post(GPT4V_ENDPOINT, headers=headers, json=payload)\n",
        "        response.raise_for_status()  # Will raise an HTTPError if the HTTP request returned an unsuccessful status code\n",
        "    except:\n",
        "        fflag = False\n",
        "        print(\"Exception\")\n",
        "        time.sleep(5)\n",
        "        pass\n",
        "\n",
        "    # Handle the response as needed (e.g., print or process)\n",
        "    if fflag:\n",
        "      response_json = response.json()\n",
        "      # print(response_json[\"choices\"][0][\"message\"][\"content\"])\n",
        "      # print(response_json[\"usage\"])\n",
        "\n",
        "      gen_text = response_json[\"choices\"][0][\"message\"][\"content\"]\n",
        "      print(\"gen text\", gen_text)\n",
        "      return gen_text\n",
        "    else:\n",
        "      return \"Error\""
      ],
      "metadata": {
        "id": "IJToL38nEUz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import math\n",
        "import time\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "data_path = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/ocr_dataset_small.json\"\n",
        "image_folder = \"/content/drive/MyDrive/ocr_data/images\"\n",
        "pad10_image_folder =  \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image10\"\n",
        "pad20_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/padded_image20\"\n",
        "master_image_folder = \"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/images\"\n",
        "\n",
        "\n",
        "annotation_path = r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/master/master_dataset.json\"\n",
        "\n",
        "# model_vicuna.to(device)\n",
        "with open(data_path, \"r\") as f:\n",
        "    data = json.load(f)\n",
        "#\n",
        "\n",
        "img_count = {}\n",
        "labels = []\n",
        "filt_data = []\n",
        "for d in data:\n",
        "  image_name = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "  if (len(filt_data) < 100):\n",
        "    if not \"signature\" in d[\"label_name\"].lower():\n",
        "      if image_name not in list(img_count.keys()):\n",
        "\n",
        "        img_count[image_name] = []\n",
        "\n",
        "      if (len(img_count[image_name])<5):\n",
        "        # else:\n",
        "        img_count[image_name].append(image_name)\n",
        "        labels.append(d[\"label_name\"])\n",
        "        filt_data.append(d)\n",
        "\n",
        "# filt_data = filt_data[:1]\n",
        "evaluated_data = []\n",
        "model_name = \"gemini-flash\"\n",
        "\n",
        "with open(annotation_path, 'r', encoding='utf8') as fin:\n",
        "    orig_annotation = json.load(fin)\n",
        "\n",
        "images = orig_annotation[\"images\"]\n",
        "annotations = orig_annotation[\"annotations\"]\n",
        "categories = orig_annotation[\"categories\"]\n",
        "\n",
        "\n",
        "unique_image_list = []\n",
        "LRVQA = []\n",
        "\n",
        "\n",
        "for d in filt_data:\n",
        "    # print(\"Data\",data[i])\n",
        "\n",
        "\n",
        "\n",
        "    img_path = os.path.join(image_folder, d['image_path'])\n",
        "\n",
        "    p_img_path = os.path.join(pad10_image_folder, d['image_path'])\n",
        "    pp_img_path = os.path.join(pad20_image_folder, d['image_path'])\n",
        "\n",
        "    root_img = d['image_path'].split(\"__\")[0]+\"__\"+d['image_path'].split(\"__\")[1].split(\"_\")[0]+\".jpg\"\n",
        "    full_img_path = os.path.join(master_image_folder, root_img )\n",
        "\n",
        "    # hwr_image = Image.open(img_path).convert(\"RGB\")\n",
        "    # p_img = Image.open(p_img_path).convert(\"RGB\")\n",
        "    # pp_img = Image.open(pp_img_path).convert(\"RGB\")\n",
        "    # full_img = Image.open(full_img_path).convert(\"RGB\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    filtered_img = [img for img in images if img[\"file_name\"] == root_img]\n",
        "    filtered_img = filtered_img[0]\n",
        "\n",
        "    filtered_id = filtered_img[\"id\"]\n",
        "\n",
        "    filtered_annotation = [ann for ann in annotations if ann[\"image_id\"] == filtered_id]\n",
        "    label_bbox = []\n",
        "    for each_ann in filtered_annotation:\n",
        "      cat_id = each_ann[\"category_id\"]\n",
        "      category_name = [cat[\"name\"] for cat in categories if cat[\"id\"] == cat_id]\n",
        "      category_name = category_name[0]\n",
        "      if category_name == d[\"label_name\"]:\n",
        "        label_bbox = each_ann[\"bbox\"]\n",
        "\n",
        "    qs = d['question']\n",
        "    qs = qs+\" Answer:\"\n",
        "    # prompt = \"Question:\" + qs + \"? Answer:\"\n",
        "\n",
        "    hwr_prompt =  qs\n",
        "\n",
        "    label_name = d[\"label_name\"]\n",
        "    label_qs = \"what is the \" + label_name + \" written in the image? Answer:\"\n",
        "    print(\"question\", qs)\n",
        "\n",
        "    bb_qs = \"what is the bounding box for \" + label_name + \"in the image?\"+  \" Answer:\"\n",
        "\n",
        "    time_qs = \"What is the difference in time between the occurrence of the event and when it was reported?\"+  \" Answer:\"\n",
        "\n",
        "    bail_qs = \"\"\"Are the charges against accused bailable or not? If any of the charges are non-bailable answer \"Non-bailable\" else \"Bailable\".\"\"\"+  \" Answer:\"\n",
        "\n",
        "    print(\"task-hwr\")\n",
        "    img_hwr = local_image_to_data_url(img_path)\n",
        "    hwr = azure_mllm(hwr_prompt,img_hwr)\n",
        "    # time.sleep(5)\n",
        "    print(\"task-phwr\")\n",
        "\n",
        "    p_img_hwr = local_image_to_data_url(p_img_path)\n",
        "    phwr = azure_mllm(hwr_prompt,p_img_hwr)\n",
        "    # time.sleep(5)\n",
        "\n",
        "    print(\"task-pphwr\")\n",
        "\n",
        "    pp_img_hwr = local_image_to_data_url(pp_img_path)\n",
        "    pphwr = azure_mllm(hwr_prompt,pp_img_hwr )\n",
        "    # time.sleep(5)\n",
        "    print(\"task-l_hwr\")\n",
        "\n",
        "\n",
        "    l_hwr = azure_mllm(label_qs,img_hwr)\n",
        "    # time.sleep(5)\n",
        "    print(\"task-l_phwr\")\n",
        "    l_phwr = azure_mllm(label_qs,p_img_hwr)\n",
        "    # time.sleep(5)\n",
        "    print(\"task-l_pphwr\")\n",
        "    l_pphwr = azure_mllm(label_qs,pp_img_hwr)\n",
        "    # time.sleep(5)\n",
        "    print(\"task-doc_vqa\")\n",
        "    full_img_hwr = local_image_to_data_url(full_img_path)\n",
        "    doc_vqa = azure_mllm(label_qs,full_img_hwr)\n",
        "    # time.sleep(5)\n",
        "    print(\"task-bb\")\n",
        "    bb_vqa = azure_mllm(bb_qs,full_img_hwr)\n",
        "    # time.sleep(5)\n",
        "\n",
        "\n",
        "\n",
        "    if full_img_path not in unique_image_list:\n",
        "      print(\"task-time\")\n",
        "      time_vqa = azure_mllm(time_qs,full_img_hwr)\n",
        "      # time.sleep(5)\n",
        "      print(\"task-bail\")\n",
        "      bail_vqa = azure_mllm(bail_qs,full_img_hwr)\n",
        "      content = {\"time_vqa\":time_vqa,\"bail_vqa\":bail_vqa,\"time_qs\":time_qs,\"bail_qs\":bail_qs,\"image_name\":full_img_path,\"time_gt\":\"\",\"bail_gt\":\"\"}\n",
        "      LRVQA.append(content)\n",
        "      unique_image_list.append(full_img_path)\n",
        "\n",
        "\n",
        "\n",
        "    ## evaluation\n",
        "    ground_truth = d[\"answers\"]\n",
        "\n",
        "    try:\n",
        "      hwr_cer_error, hwr_wer_error = cer_wer(hwr, ground_truth)\n",
        "    except:\n",
        "      hwr_cer_error, hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      phwr_cer_error, phwr_wer_error = cer_wer(phwr, ground_truth)\n",
        "    except:\n",
        "      phwr_cer_error, phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      pphwr_cer_error, pphwr_wer_error = cer_wer(pphwr, ground_truth)\n",
        "    except:\n",
        "      pphwr_cer_error, pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = cer_wer(l_hwr, ground_truth)\n",
        "    except:\n",
        "      l_hwr_cer_error, l_hwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = cer_wer(l_phwr, ground_truth)\n",
        "    except:\n",
        "      l_phwr_cer_error, l_phwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = cer_wer(l_pphwr, ground_truth)\n",
        "    except:\n",
        "      l_pphwr_cer_error, l_pphwr_wer_error = 100,100\n",
        "\n",
        "    try:\n",
        "      doc_vqa_cer_error, doc_vqa_wer_error = cer_wer(doc_vqa, ground_truth)\n",
        "    except:\n",
        "      doc_vqa_cer_error, doc_vqa_wer_error = 100,100\n",
        "\n",
        "    d[\"hwr_cer\"] = hwr_cer_error\n",
        "    d[\"hwr_wer\"] = hwr_wer_error\n",
        "    d[\"hwr_model_output\"] = hwr\n",
        "    d[\"hwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"phwr_cer\"] = phwr_cer_error\n",
        "    d[\"phwr_wer\"] = phwr_wer_error\n",
        "    d[\"phwr_model_output\"] = phwr\n",
        "    d[\"phwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"pphwr_cer\"] = pphwr_cer_error\n",
        "    d[\"pphwr_wer\"] = pphwr_wer_error\n",
        "    d[\"pphwr_model_output\"] = pphwr\n",
        "    d[\"pphwr_prompt\"] = hwr_prompt\n",
        "\n",
        "    d[\"l_hwr_cer\"] = l_hwr_cer_error\n",
        "    d[\"l_hwr_wer\"] = l_hwr_wer_error\n",
        "    d[\"l_hwr_model_output\"] = l_hwr\n",
        "    d[\"l_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_phwr_cer\"] = l_phwr_cer_error\n",
        "    d[\"l_phwr_wer\"] = l_phwr_wer_error\n",
        "    d[\"l_phwr_model_output\"] = l_phwr\n",
        "    d[\"l_phwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"l_pphwr_cer\"] = l_pphwr_cer_error\n",
        "    d[\"l_pphwr_wer\"] = l_pphwr_wer_error\n",
        "    d[\"l_pphwr_model_output\"] = l_pphwr\n",
        "    d[\"l_pphwr_hwr_prompt\"] = label_qs\n",
        "\n",
        "    d[\"doc_vqa_cer\"] = doc_vqa_cer_error\n",
        "    d[\"doc_vqa_wer\"] = doc_vqa_wer_error\n",
        "    d[\"doc_vqa_model_output\"] = doc_vqa\n",
        "    d[\"doc_vqa_hwr_prompt\"] = label_qs\n",
        "\n",
        "\n",
        "\n",
        "    d[\"bbox_model_output\"] = bb_vqa\n",
        "    d[\"bbox_hwr_prompt\"] = bb_qs\n",
        "\n",
        "    d[\"model_name\"] = model_name\n",
        "\n",
        "    evaluated_data.append(d)\n",
        "\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_HWR-25\"}.json'), 'w') as outfile:\n",
        "    json.dump(evaluated_data, outfile)\n",
        "\n",
        "print(LRVQA)\n",
        "LRVQA = json.dumps(LRVQA)\n",
        "# if not os.path.exists(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA\"}.json')):\n",
        "with open(os.path.join(r\"/content/drive/MyDrive/My_PhD_Research/FIR_FORM/datasets/OCR/eval_output\",f'{model_name+\"_LRVQA-25\"}.json'), 'w') as outfile:\n",
        "    json.dump(LRVQA,outfile)"
      ],
      "metadata": {
        "id": "Q9-swFGGTjDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_records(data,index=['1', '2'])\n",
        "print(df)"
      ],
      "metadata": {
        "id": "C5DN4XqcR2Y8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}